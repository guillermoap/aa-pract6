{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 5.2 - Damas chinas con Redes Neuronales\n",
    "\n",
    "### Grupo 6:\n",
    "     - Guillermo Aguirre  C.I. 4817028-5\n",
    "     - Bruno González C.I. 4815697-6\n",
    "     - Mauricio Irace C.I. 4924714-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En anteriores entregas se hicieron dos jugadores, uno entrenado contra un jugador que movia al azar, y otro que aprendio jugando contra el resultado del entrenamiento anterior. \n",
    "\n",
    "En esta entrega, se repetira el procedimiento, pero utilizando redes neuronales en vez de una lineal para calcular la función $V:Tablero\\rightarrow[-1, 1]$, que determina el valor de un tablero\n",
    "\n",
    "El éxito del aprendizaje se mide, al igual que en la primera tarea, haciendolo competir con versiones anteriores del mismo. Por supuesto, en este caso, hablamos de los dos jugadores de la primera tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Arquitectura de Red Neuronal\n",
    "\n",
    "Se utilizo como entrada de la red neuronal los mismos cuatro valores que en la primer entrega:\n",
    "\n",
    "$$ (x_1, x_2, x_3, x_4) $$\n",
    "\n",
    "Donde:\n",
    "\n",
    "$x_1=$ Cantidad de fichas propias en la zona objetivo\n",
    "\n",
    "$x_2=$ Cantidad de fichas del contrincante en la zona objetivo\n",
    "\n",
    "$x_3=$ Suma de la distancias euclideas de todas las fichas propias al objetivo\n",
    "\n",
    "$x_4=$ Suma de la distancias euclideas de todas las fichas contrincantes al objetivo\n",
    "\n",
    "Claramente, los valores de $ B_{good} = (x_1, x_4)$ favorecen al jugador, mientras que los de $ B_{bad} = (x_2, x_3)$ representan variables a minimizar. \n",
    "\n",
    "    En ese sentido, se opto por hacer dos subredes, cada una recibe una de las dos tuplas, la envía por una capa densa utilizando relu como función de activación, y luego tanh, llevando al deseado intervalo de salida [-1, 1] Los resultados se combinan restando, y se le vuelve a aplicar tangente hiperbólica para normalizar.\n",
    "\n",
    "Tambien se probó utilizar todo el tablero como entrada, utilizando capas convolucionales. De esta forma, y dado los resultados positivos que estas suelen tener con aspectos visuales (como el tablero), se esperaba un resultado favorable. Finalmente se descartó por la complejidad que estaba conllevando, así como el exceso de información en el modelo\n",
    "    \n",
    "A continuación, se presenta el sumario de la red generado por Keras:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "input_1 (InputLayer)            (None, 2)            0                                            \n",
    "__________________________________________________________________________________________________\n",
    "input_2 (InputLayer)            (None, 2)            0                                            \n",
    "__________________________________________________________________________________________________\n",
    "dense_1 (Dense)                 (None, 4)            12          input_1[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "dense_3 (Dense)                 (None, 4)            12          input_2[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "dense_2 (Dense)                 (None, 1)            5           dense_1[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "dense_4 (Dense)                 (None, 1)            5           dense_3[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "subtract_1 (Subtract)           (None, 1)            0           dense_2[0][0]                    \n",
    "                                                                 dense_4[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "dense_5 (Dense)                 (None, 1)            2           subtract_1[0][0]                 \n",
    "==================================================================================================\n",
    "Total params: 36\n",
    "Trainable params: 36\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Entrenamiento\n",
    "En principio no se obtuvieron buenos resultados. El jugador no sabia realmente que hacer, y no salía de su zona. \n",
    "\n",
    "A continuación decidimos pre entrenar la red, enseñandole casos de perdida y victoria.\n",
    "\n",
    "Se utilizo además el concepto de tasa de exploración, que se va reduciendo hasta un mínimo a medida que el jugador aprende. A mayor esta tasa, mayor la probabildiad de efectuar jugadas al azar, que sirven para probare nuevas estrategias, al costo de arriesgarse a cometer errores.\n",
    "\n",
    "Gracias a lo expuesto en los dos párrafos anteriores, pudimos lograr que el jugador realmente se moviera y aprendiera.\n",
    "\n",
    "Dado que en principio el jugador realizaba jugadas en falso por obvias razones, se prefirio optar utilizar un limite alto de jugadas (que terminó en los 3000) y un limite pequeño de partidas para evitar overfiting (en su última versión se utilizo un valor de 10, pero 5 partidas dieron resultados similares). Cada 5 partidas, se reemplazaba el jugador anterior (en principio aleatorio) por el entrenado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtuvieron los siguientes resultados contra los jugadores de la tarea 1.\n",
    "\n",
    "| Oponente entrenado contra  \t| Gano Neural \t| Empate \t| Perdio Neural \t|\n",
    "|------------------\t|-------------\t|--------\t|---------------\t|\n",
    "| Random    \t| 33          \t| 34     \t| 33            \t|\n",
    "| No-Random \t| 37          \t| 29     \t| 34            \t|\n",
    "\n",
    "Recordemos que los mejores resultados, por alguna razón, en la primera tarea se dieron con el jugador que aprendió contra un oponente aleatorio, siendo lógico entonces que sea este el que más pelea dío. \n",
    "\n",
    "Lo extraño es que sea un empate técnico (Ganaron, empataron, y perdieron un tercio de las partidas cada uno). Esto nos da a entender, que no hubo diferencias entre el resultado un entrenamiento y otro.\n",
    "\n",
    "Por otro lado, jugó mejor que el otro jugador de la tarea 1, aunque no por mucho.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados no han variado mucho con respecto a la primer tarea. \n",
    "\n",
    "Creemos que una experimentación mas extensiva con las redes neuronales, podría haber mejorado los resultados. Esto incluye incluir experimentos que descartamos como las redes convolucionales, o features descartadas de la tarea anterior (como la cantidad de saltos de un jugador).\n",
    "\n",
    "A su vez, al usar ReLu como función de activación descartamos toda variación negativa que pase por estas neuronas, por lo que puede estuvieramos perdiendo información importante. Aunque probamos con otras funciones tradicionales, es posible que una mayor experimentacipon hubiera sido favorable. \n",
    "\n",
    "Aún así, encontramos que la técnica de trabajo utiliado fue razonable y métodica, sin perder la importancia de la experimentación, lo que, recordando que tomamos como base el trabajo anterior, y los resultados obtenidos, se puede decir que se obtuvo una pequeña mejora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
